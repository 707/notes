// [NOT-46] AI Harness - Main Entry Point
// Provides a unified interface for AI interactions with pluggable providers
// This architecture allows easy switching between providers (OpenRouter, Gemini Nano, etc.)

// [NOT-51] Smart Fallback Chain - Auto-generated from OpenRouter API
// The model chain is now loaded from free-models.js (generated by scripts/fetch-free-models.js)
// To update models: run `node scripts/fetch-free-models.js`
// Models are sorted by context window size (largest first) and include only free text-only models
// The FREE_MODEL_CHAIN constant is provided by window.FREE_MODEL_CHAIN (loaded via script tag)

/**
 * AI Harness - Manages AI provider selection and message routing
 * Implements a plugin architecture for multiple AI providers
 */
class AIHarness {
  constructor() {
    this.currentProvider = null;
    this.availableProviders = {
      openrouter: null // Will be initialized lazily
    };
  }

  /**
   * Initialize the harness with a specific provider
   * @param {string} providerName - Provider name ("openrouter", "gemini", etc.)
   * @returns {Promise<boolean>} - Returns true if initialization successful
   */
  async initialize(providerName = 'openrouter') {
    try {
      console.log(`üîå [NOT-46] Initializing AI Harness with provider: ${providerName}`);

      // Initialize OpenRouter provider
      if (providerName === 'openrouter') {
        if (!this.availableProviders.openrouter) {
          // Check if OpenRouterProvider is loaded
          if (typeof OpenRouterProvider === 'undefined') {
            throw new Error('OpenRouterProvider not loaded');
          }
          this.availableProviders.openrouter = new OpenRouterProvider();
        }

        const hasKey = await this.availableProviders.openrouter.initialize();
        if (!hasKey) {
          console.warn('‚ö†Ô∏è  [NOT-46] OpenRouter API key not configured');
          return false;
        }

        this.currentProvider = this.availableProviders.openrouter;
        console.log('‚úÖ [NOT-46] OpenRouter provider initialized');
        return true;
      }

      throw new Error(`Unknown provider: ${providerName}`);
    } catch (error) {
      console.error('‚ùå [NOT-46] Failed to initialize AI Harness:', error);
      return false;
    }
  }

  /**
   * Send a message and receive streaming response
   * [NOT-51] Now implements smart fallback chain when modelId is 'auto'
   * [NOT-79] Enforces structured JSON response format: { thought, content, actions }
   * @param {string} text - User message text
   * @param {Object} context - Optional context (previous messages, model, etc.)
   * @param {Function} onChunk - Callback for streaming response chunks
   * @param {Function} onComplete - Callback when response is complete
   * @param {Function} onError - Callback on error
   * @returns {Promise<void>}
   */
  async sendMessage(text, context = {}, onChunk, onComplete, onError) {
    // Ensure provider is initialized
    if (!this.currentProvider) {
      const initialized = await this.initialize('openrouter');
      if (!initialized) {
        onError(new Error('Failed to initialize AI provider. Please check your API key in Settings.'));
        return;
      }
    }

    try {
      // Build messages array from context
      const messages = context.messages || [];

      // [NOT-79] Prepend system message with structured response format instruction
      // Only add if there isn't already a system message in the history
      const hasSystemMessage = messages.some(m => m.role === 'system');
      if (!hasSystemMessage) {
        messages.unshift({
          role: 'system',
          content: `You must respond in JSON format with the following structure:
{
  "thought": "Your internal reasoning about how to answer this question",
  "content": "The actual message to show the user",
  "actions": []
}

The "thought" field is for your internal reasoning and will not be shown to the user.
The "content" field is what the user will see as your response.
The "actions" field is reserved for future agentic capabilities (leave empty for now).

IMPORTANT: Return ONLY the JSON object. Do not include markdown code blocks or any other text.`
        });
      }

      // Add user message
      messages.push({
        role: 'user',
        content: text
      });

      // Get model ID from context or use default
      const requestedModelId = context.modelId || 'auto';

      // [NOT-51] Determine which models to try based on user preference
      let modelsToTry = [];
      if (requestedModelId === 'auto') {
        // Use the smart fallback chain
        modelsToTry = FREE_MODEL_CHAIN.map(m => m.id);
        console.log('üéØ [NOT-51] Using smart fallback chain with', modelsToTry.length, 'models');
      } else {
        // User selected a specific model - only try that one
        modelsToTry = [requestedModelId];
      }

      // [NOT-51] Try each model in the chain until one succeeds
      let lastError = null;
      let streamStarted = false;

      for (let i = 0; i < modelsToTry.length; i++) {
        const modelId = modelsToTry[i];
        const isLastModel = i === modelsToTry.length - 1;

        console.log(`üí¨ [NOT-51] Attempting model ${i + 1}/${modelsToTry.length}: ${modelId}`);

        try {
          // Wrap callback-based provider API in a Promise
          await new Promise((resolve, reject) => {
            // Track if streaming has started (first chunk received)
            let hasReceivedFirstChunk = false;

            this.currentProvider.sendMessage(
              messages,
              modelId,
              // onChunk wrapper
              (chunk) => {
                if (!hasReceivedFirstChunk) {
                  hasReceivedFirstChunk = true;
                  streamStarted = true;
                  console.log(`‚úÖ [NOT-51] Stream started successfully with ${modelId}`);
                }
                onChunk(chunk);
              },
              // onComplete wrapper
              () => {
                console.log(`‚úÖ [NOT-51] Message completed successfully with ${modelId}`);
                onComplete();
                resolve();
              },
              // onError wrapper
              (error) => {
                // If stream already started, don't retry (partial response received)
                if (hasReceivedFirstChunk) {
                  console.error(`‚ùå [NOT-51] Stream failed mid-response with ${modelId}:`, error);
                  onError(error);
                  resolve(); // Don't retry - user already saw partial response
                } else {
                  // Stream never started - this is a retriable error
                  console.warn(`‚ö†Ô∏è  [NOT-51] Model ${modelId} failed before streaming:`, error.message);
                  lastError = error;
                  reject(error);
                }
              }
            );
          });

          // If we get here, the message succeeded
          return;

        } catch (error) {
          lastError = error;

          // If this is the last model, propagate the error
          if (isLastModel) {
            console.error(`‚ùå [NOT-51] All models exhausted. Last error:`, error);
            onError(new Error(`All models failed. Last error: ${error.message}`));
            return;
          }

          // Otherwise, log and continue to next model
          console.log(`üîÑ [NOT-51] Retrying with next model in chain...`);
        }
      }

    } catch (error) {
      console.error('‚ùå [NOT-51] Error in sendMessage:', error);
      onError(error);
    }
  }

  /**
   * Get list of available models for current provider
   * [NOT-51] Returns the full fallback chain plus an 'auto' option
   * @returns {Array} - Array of model objects with id, name, and description
   */
  getAvailableModels() {
    // [NOT-51] Return 'auto' option first (recommended), then all individual models
    return [
      {
        id: 'auto',
        name: 'Smart Auto (Recommended)',
        description: 'Intelligent fallback chain prioritized by context window'
      },
      ...FREE_MODEL_CHAIN
    ];
  }

  /**
   * [NOT-59] Extract structured data from text using AI
   * Enforces JSON output format for metadata extraction
   *
   * @param {string} text - The text to analyze (page content, etc.)
   * @param {Object} schema - Optional schema describing expected fields
   * @param {Object} options - Optional configuration (modelId, etc.)
   * @returns {Promise<Object>} - Parsed JSON object with extracted metadata
   */
  async extractStructuredData(text, schema = {}, options = {}) {
    // Ensure provider is initialized
    if (!this.currentProvider) {
      const initialized = await this.initialize('openrouter');
      if (!initialized) {
        throw new Error('Failed to initialize AI provider. Please check your API key in Settings.');
      }
    }

    try {
      console.log('üß† [NOT-59] Extracting structured data...');

      // [NOT-59] Adaptive Context Logic - check model context window
      const modelId = options.modelId || 'auto';
      let processedText = text;

      // If using auto mode, check the first model's context window
      if (modelId === 'auto' && FREE_MODEL_CHAIN.length > 0) {
        const firstModel = FREE_MODEL_CHAIN[0];
        console.log(`üìä [NOT-59] Model context window: ${firstModel.contextWindow}`);

        // Small brain (<16k): activate compression mode
        if (firstModel.contextWindow < 16000) {
          console.log('üîÑ [NOT-59] Small context detected - activating compression mode');
          // Truncate to first 8k characters to fit within small context
          processedText = text.substring(0, 8000);
          if (text.length > 8000) {
            processedText += '...\n[Content truncated due to model limitations]';
          }
        } else {
          console.log('‚úÖ [NOT-59] Large context detected - sending full text');
        }
      }

      // [NOT-59] Construct system prompt that enforces JSON output
      const systemPrompt = `You are a metadata extractor. Your task is to analyze the given text and extract structured metadata as a JSON object.

Extract the following fields if they are present or can be inferred:
- type: Content type (article, video, repo, tutorial, documentation, etc.)
- summary: A brief 1-2 sentence summary
- topics: Array of main topics or keywords (max 5)
- readingTime: Estimated reading time (e.g., "5 min read")
- difficulty: Content difficulty level (beginner, intermediate, advanced) if applicable
- language: Programming language if code-related

Additional domain-specific fields:
- For GitHub repos: stars, language, owner, repo, topics
- For YouTube videos: duration, channel, views, uploadDate
- For articles: author, publishDate, category

Return ONLY valid JSON. Do not include markdown formatting, code blocks, or explanations.`;

      // Build messages array
      const messages = [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: `Extract metadata from the following content:\n\n${processedText}`
        }
      ];

      // Track the response
      let responseText = '';
      let completed = false;
      let error = null;

      // Call provider with streaming disabled for JSON extraction
      await new Promise((resolve, reject) => {
        this.currentProvider.sendMessage(
          messages,
          modelId,
          // onChunk - accumulate response
          (chunk) => {
            responseText += chunk;
          },
          // onComplete
          () => {
            completed = true;
            resolve();
          },
          // onError
          (err) => {
            error = err;
            reject(err);
          }
        );
      });

      if (error) {
        throw error;
      }

      console.log('üì• [NOT-59] Raw AI response:', responseText);

      // [NOT-59] Robust JSON parsing - handle markdown code blocks
      let parsedData;
      try {
        // First, try to extract JSON from markdown code blocks
        const codeBlockMatch = responseText.match(/```(?:json)?\s*(\{[\s\S]*\})\s*```/);
        if (codeBlockMatch) {
          console.log('üì¶ [NOT-59] Found JSON in code block');
          parsedData = JSON.parse(codeBlockMatch[1]);
        } else {
          // Try to find JSON object in the response
          const jsonMatch = responseText.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            console.log('üì¶ [NOT-59] Found JSON object in response');
            parsedData = JSON.parse(jsonMatch[0]);
          } else {
            // Last resort: try parsing the entire response
            parsedData = JSON.parse(responseText);
          }
        }

        console.log('‚úÖ [NOT-59] Successfully parsed JSON:', parsedData);
        return parsedData;

      } catch (parseError) {
        console.error('‚ùå [NOT-59] Failed to parse JSON response:', parseError);
        console.error('Response was:', responseText);
        throw new Error(`Failed to parse AI response as JSON: ${parseError.message}`);
      }

    } catch (error) {
      console.error('‚ùå [NOT-59] Error extracting structured data:', error);
      throw error;
    }
  }

  /**
   * Test if current provider is configured correctly
   * @returns {Promise<boolean>} - Returns true if provider is ready
   */
  async testProvider() {
    if (!this.currentProvider) {
      return false;
    }

    try {
      if (this.currentProvider.testApiKey) {
        return await this.currentProvider.testApiKey();
      }
      return true;
    } catch (error) {
      console.error('‚ùå [NOT-46] Provider test failed:', error);
      return false;
    }
  }
}

// Export global instance
window.aiHarness = new AIHarness();
console.log('‚úÖ [NOT-46] AI Harness loaded');
